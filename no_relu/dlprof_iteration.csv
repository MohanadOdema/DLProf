Iteration Report
Iteration,Op ID,Op Name,Direction,Op Type,Kernel Name,Device ID,GPU Start Time (ns),GPU Duration (ns),API Call Start (ns),API Call Time (ns),Uses TC,Grid X,Grid Y,Grid Z,Block X,Block Y,Block Z,Data Types,Input Shapes,Parameters,Output Shapes,Long Kernel Name
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","computeOffsetsKernel",0,2860736409,2176,2860729860,5811,no,8,1,1,128,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","cudnn::gemm::computeOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","compute_gemm_pointers",0,2860879928,2144,2860875308,3457,no,544,1,1,1,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","compute_gemm_pointers(float2 **, const float2 *, int, const float2 *, int, const float2 *, int, int)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","explicit_convolve_sgemm",0,2860799736,5280,2860789673,8904,no,29,1,1,8,8,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void cudnn::detail::explicit_convolve_sgemm<float, int, (int)1024, (int)5, (int)5, (int)3, (int)3, (int)3, (int)0, (bool)1>(int, int, int, const T1 *, int, const T1 *, int, T1 *, kernel_conv_params, int, int, float, float, int, T1 *, T1 *)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","fft2d_c2r_32x32",0,2860896408,6272,2860891287,3592,no,1,1,1,512,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void fft2d_c2r_32x32<float, (bool)0, (bool)0, (unsigned int)0, (bool)0, (bool)0>(T1 *, const float2 *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, T1 *, T1 *, int2, int, int)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","fft2d_c2r_32x32",0,2860972472,5856,2860965002,2968,no,1,1,1,512,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void fft2d_c2r_32x32<float, (bool)0, (bool)0, (unsigned int)0, (bool)0, (bool)0>(T1 *, const float2 *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, T1 *, T1 *, int2, int, int)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","fft2d_r2c_32x32",0,2860865464,10656,2860860281,4366,no,2,1,1,512,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void fft2d_r2c_32x32<float, (bool)0, (unsigned int)0, (bool)0>(float2 *, const T1 *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","fft2d_r2c_32x32",0,2860871480,4480,2860865383,4985,no,1,1,1,512,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void fft2d_r2c_32x32<float, (bool)0, (unsigned int)0, (bool)0>(float2 *, const T1 *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","fft2d_r2c_32x32",0,2860952984,10144,2860947568,4462,no,2,1,1,512,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void fft2d_r2c_32x32<float, (bool)0, (unsigned int)0, (bool)0>(float2 *, const T1 *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","fft2d_r2c_32x32",0,2860958520,4352,2860954397,2974,no,1,1,1,512,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void fft2d_r2c_32x32<float, (bool)0, (unsigned int)0, (bool)0>(float2 *, const T1 *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","flip_filter",0,2860859832,2048,2860854306,4690,no,6,3,1,3,3,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void flip_filter<float, float>(T2 *, const T1 *, int, int, int, int)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","gemmSN_NN_kernel",0,2861074552,9215,2861069336,4336,no,16,2,36,128,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void gemmSN_NN_kernel<float, (int)128, (int)2, (int)4, (int)8, (int)3, (int)4, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T8, T9, T1>)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","gemv2N_kernel",0,2860966296,5632,2860960504,3441,no,1,1,544,128,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void gemv2N_kernel<int, int, float2, float2, float2, (int)128, (int)8, (int)4, (int)4, (int)1, cublasGemvParams<cublasGemvTensorStridedBatched<const float2>, cublasGemvTensorStridedBatched<float2>, float2>>(T11)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","gemv2T_kernel_val",0,2860890488,5312,2860885916,3902,no,1,1,544,128,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void gemv2T_kernel_val<int, int, float2, float2, float2, (int)128, (int)16, (int)2, (int)2, (bool)0, cublasGemvParams<cublasGemvTensorBatched<const float2>, cublasGemvTensorBatched<float2>, float2>>(T11, T5, T5)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","generateWinogradTilesKernel",0,2861022008,2304,2861015608,5890,no,1,2,1,32,4,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void cudnn::winograd::generateWinogradTilesKernel<(int)0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<T2, T3>)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","im2col4d_kernel",0,2860785144,6304,2860779664,4768,no,2,1,1,512,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void im2col4d_kernel<float, int>(im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, const T1 *, T1 *, int)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","implicit_convolve_sgemm",0,2860585945,5696,2860565780,21059,no,29,1,1,8,8,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void cudnn::detail::implicit_convolve_sgemm<float, float, (int)1024, (int)5, (int)5, (int)3, (int)3, (int)3, (int)1, (bool)1, (bool)0, (bool)1>(int, int, int, const T1 *, int, T2 *, T1 *, kernel_conv_params, int, float, float, int, T2 *, T2 *, int, int)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","implicit_convolve_sgemm",0,2860655673,5312,2860647985,6932,no,29,1,1,8,8,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void cudnn::detail::implicit_convolve_sgemm<float, float, (int)1024, (int)5, (int)5, (int)3, (int)3, (int)3, (int)1, (bool)1, (bool)0, (bool)1>(int, int, int, const T1 *, int, T2 *, T1 *, kernel_conv_params, int, float, float, int, T2 *, T2 *, int, int)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","implicit_convolve_sgemm",0,2861135927,5088,2861127908,7015,no,29,1,1,8,8,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void cudnn::detail::implicit_convolve_sgemm<float, float, (int)1024, (int)5, (int)5, (int)3, (int)3, (int)3, (int)1, (bool)1, (bool)0, (bool)1>(int, int, int, const T1 *, int, T2 *, T1 *, kernel_conv_params, int, float, float, int, T2 *, T2 *, int, int)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","unrolled_elementwise_kernel",0,2861208439,3200,2861200785,6739,no,22,1,1,64,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, float, at::native::AddFunctor<float>>, at::detail::Array<char *, (int)3>, OffsetCalculator<(int)2, unsigned int, (bool)0>, OffsetCalculator<(int)1, unsigned int, (bool)0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, T1, T2, T3, T4, T5, T6)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","volta_scudnn_128x32_relu_interior_nn_v1",0,2860744376,10144,2860738670,4588,no,8,1,1,64,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","volta_scudnn_128x32_relu_interior_nn_v1"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1",0,2861027288,7423,2861022526,3549,no,1,4,2,256,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","winogradForwardData4x4",0,2861063640,4032,2861058139,4713,no,4,3,1,256,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<T1, T2>)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","winogradForwardFilter4x4",0,2861068343,2560,2861063193,3113,no,1,1,1,32,8,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<T1, T2>)"
0,"CONV2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","winogradForwardOutput4x4",0,2861084471,3968,2861074548,2911,no,4,6,1,256,1,1,float32,"<N:1, C:3, H:32, W:32>; <K:6, C:3, R:3, S:3>; <6>","","<N:1, K:6, P:30, Q:30>","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<T1, T2>)"
0,"MAX_POOL2D_1","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl/Conv2d::forward/max_pool2d",fprop,"max_pool2d","max_pool_forward_nchw",0,2861854517,2624,2861845275,9374,no,6,1,1,256,1,1,float32,"<1, 6, 30, 30>","","","void at::native::<unnamed>::max_pool_forward_nchw<float, float>(int, const T1 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int, T1 *, long *)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","computeOffsetsKernel",0,2862141492,1952,2862135648,4709,no,1,1,1,128,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","cudnn::gemm::computeOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","compute_gemm_pointers",0,2862269172,1888,2862264599,3419,no,144,1,1,1,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","compute_gemm_pointers(float2 **, const float2 *, int, const float2 *, int, const float2 *, int, int)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","explicit_convolve_sgemm",0,2862214292,9024,2862198730,9137,no,4,1,1,8,8,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void cudnn::detail::explicit_convolve_sgemm<float, int, (int)128, (int)5, (int)5, (int)3, (int)3, (int)3, (int)0, (bool)1>(int, int, int, const T1 *, int, const T1 *, int, T1 *, kernel_conv_params, int, int, float, float, int, T1 *, T1 *)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","fft2d_c2r_16x16",0,2862278132,5856,2862273258,3511,no,1,1,1,256,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void fft2d_c2r_16x16<float, (bool)0>(T1 *, float2 *, int, int, int, int, int, int, int, int, int, int, float, float, int, T1 *, T1 *)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","fft2d_c2r_32x32",0,2862335859,9601,2862328929,3848,no,1,1,1,512,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void fft2d_c2r_32x32<float, (bool)0, (bool)0, (unsigned int)1, (bool)0, (bool)0>(T1 *, const float2 *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, T1 *, T1 *, int2, int, int)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","fft2d_r2c_16x16",0,2862258292,3680,2862253299,3960,no,1,16,1,256,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void fft2d_r2c_16x16<float>(float2 *, const T1 *, int, int, int, int, int, int, int, int)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","fft2d_r2c_16x16",0,2862262164,3200,2862257714,2971,no,1,1,1,256,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void fft2d_r2c_16x16<float>(float2 *, const T1 *, int, int, int, int, int, int, int, int)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","fft2d_r2c_32x32",0,2862318004,8704,2862312341,4981,no,6,1,1,512,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void fft2d_r2c_32x32<float, (bool)0, (unsigned int)1, (bool)0>(float2 *, const T1 *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","fft2d_r2c_32x32",0,2862323379,5472,2862319473,2936,no,1,1,1,512,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void fft2d_r2c_32x32<float, (bool)0, (unsigned int)1, (bool)0>(float2 *, const T1 *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","flip_filter",0,2862253460,1984,2862248567,3887,no,16,6,1,5,5,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void flip_filter<float, float>(T2 *, const T1 *, int, int, int, int)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","gemmSN_NN_kernel",0,2862374227,10560,2862367209,3830,no,1,4,169,128,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void gemmSN_NN_kernel<float, (int)128, (int)2, (int)4, (int)8, (int)4, (int)4, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T8, T9, T1>)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","gemv2N_kernel",0,2862329812,5504,2862324352,3164,no,1,1,544,128,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void gemv2N_kernel<int, int, float2, float2, float2, (int)128, (int)8, (int)4, (int)4, (int)1, cublasGemvParams<cublasGemvTensorStridedBatched<const float2>, cublasGemvTensorStridedBatched<float2>, float2>>(T11)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","gemv2T_kernel_val",0,2862273524,3936,2862269234,3027,no,2,1,144,128,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void gemv2T_kernel_val<int, int, float2, float2, float2, (int)128, (int)16, (int)2, (int)2, (bool)0, cublasGemvParams<cublasGemvTensorBatched<const float2>, cublasGemvTensorBatched<float2>, float2>>(T11, T5, T5)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","im2col4d_kernel",0,2862195444,17984,2862190431,3985,no,1,1,1,512,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void im2col4d_kernel<float, int>(im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, const T1 *, T1 *, int)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","implicit_convolve_sgemm",0,2862055796,10848,2862042948,12316,no,4,1,1,8,8,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void cudnn::detail::implicit_convolve_sgemm<float, float, (int)1024, (int)5, (int)5, (int)3, (int)3, (int)3, (int)1, (bool)1, (bool)0, (bool)1>(int, int, int, const T1 *, int, T2 *, T1 *, kernel_conv_params, int, float, float, int, T2 *, T2 *, int, int)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","implicit_convolve_sgemm",0,2862098932,10688,2862091692,6360,no,4,1,1,8,8,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void cudnn::detail::implicit_convolve_sgemm<float, float, (int)1024, (int)5, (int)5, (int)3, (int)3, (int)3, (int)1, (bool)1, (bool)0, (bool)1>(int, int, int, const T1 *, int, T2 *, T1 *, kernel_conv_params, int, float, float, int, T2 *, T2 *, int, int)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","implicit_convolve_sgemm",0,2862508051,11008,2862499246,7963,no,4,1,1,8,8,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void cudnn::detail::implicit_convolve_sgemm<float, float, (int)1024, (int)5, (int)5, (int)3, (int)3, (int)3, (int)1, (bool)1, (bool)0, (bool)1>(int, int, int, const T1 *, int, T2 *, T1 *, kernel_conv_params, int, float, float, int, T2 *, T2 *, int, int)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","unrolled_elementwise_kernel",0,2862538867,3264,2862532244,5479,no,8,1,1,64,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, float, at::native::AddFunctor<float>>, at::detail::Array<char *, (int)3>, OffsetCalculator<(int)2, unsigned int, (bool)0>, OffsetCalculator<(int)1, unsigned int, (bool)0>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, T1, T2, T3, T4, T5, T6)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","volta_scudnn_128x64_relu_interior_nn_v1",0,2862148052,20832,2862142902,4124,no,1,1,1,128,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","volta_scudnn_128x64_relu_interior_nn_v1"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","winogradForwardData9x9_5x5",0,2862362227,7265,2862356962,4680,no,2,6,1,936,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void cudnn::winograd_nonfused::winogradForwardData9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDataParams<T1, T2>)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","winogradForwardFilter9x9_5x5",0,2862370163,3360,2862361963,3131,no,1,16,1,64,13,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void cudnn::winograd_nonfused::winogradForwardFilter9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<T1, T2>)"
0,"CONV2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/Conv2d::_conv_forward/conv2d",fprop,"conv2d","winogradForwardOutput9x9_5x5",0,2862385331,6400,2862371914,3122,no,2,16,1,936,1,1,float32,"<N:1, C:6, H:15, W:15>; <K:16, C:6, R:5, S:5>; <16>","","<N:1, K:16, P:11, Q:11>","void cudnn::winograd_nonfused::winogradForwardOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<T1, T2>)"
0,"MAX_POOL2D_2","/module/dummy_network::_call_impl/dummy_network::forward/Conv2d::_call_impl[2]/Conv2d::forward/max_pool2d",fprop,"max_pool2d","max_pool_forward_nchw",0,2862860818,3424,2862851875,8109,no,2,1,1,256,1,1,float32,"<1, 16, 11, 11>","","","void at::native::<unnamed>::max_pool_forward_nchw<float, float>(int, const T1 *, int, int, int, int, int, int, int, int, int, int, int, int, int, int, T1 *, long *)"
0,"LINEAR_1","/module/dummy_network::_call_impl/dummy_network::forward/Linear::_call_impl[3]/Linear::forward/linear",fprop,"linear","gemv2T_kernel_val",0,2863558064,4032,2863549697,8326,no,15,1,1,128,1,1,float32,"<N:1, K:400>; <M:120, K:400>; <120>","","<N:1, M:120>","void gemv2T_kernel_val<int, int, float, float, float, (int)128, (int)16, (int)4, (int)4, (bool)0, cublasGemvParams<cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T11, T5, T5)"
0,"LINEAR_2","/module/dummy_network::_call_impl/dummy_network::forward/Linear::_call_impl[4]/Linear::forward/linear",fprop,"linear","gemv2T_kernel_val",0,2863821999,3200,2863815899,5527,no,11,1,1,128,1,1,float32,"<N:1, K:120>; <M:84, K:120>; <84>","","<N:1, M:84>","void gemv2T_kernel_val<int, int, float, float, float, (int)128, (int)16, (int)4, (int)4, (bool)0, cublasGemvParams<cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T11, T5, T5)"
0,"LINEAR_3","/module/dummy_network::_call_impl/dummy_network::forward/Linear::_call_impl[5]/Linear::forward/linear",fprop,"linear","gemv2T_kernel_val",0,2864062990,3072,2864057209,5556,no,2,1,1,128,1,1,float32,"<N:1, K:84>; <M:10, K:84>; <10>","","<N:1, M:10>","void gemv2T_kernel_val<int, int, float, float, float, (int)128, (int)16, (int)2, (int)2, (bool)0, cublasGemvParams<cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T11, T5, T5)"
